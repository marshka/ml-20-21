{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_unsupervised_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fJl2L7sNQ-zX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marshka/ml-20-21/blob/main/07_unsupervised_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6oJGO3smnq"
      },
      "source": [
        "# Machine Learning SP 2020/2021\n",
        "\n",
        "Prof. Cesare Alippi   \n",
        "Andrea Cini ([`andrea.cini@usi.ch`](mailto:andrea.cini@usi.ch))   \n",
        "Ivan Marisca ([`ivan.marisca@usi.ch`](mailto:ivan.marisca@usi.ch))   \n",
        "Nelson Brochado ([`nelson.brochado@usi.ch`](mailto:nelson.brochado@usi.ch))\n",
        "\n",
        "---\n",
        "# Lab 07: Unsupervised learning\n",
        "\n",
        "In this lab, we will see practical applications of unsupervised learning techniques. \n",
        "\n",
        "We will focus on two main tasks: \n",
        "\n",
        "1. Clustering;\n",
        "3. Dimensionality reduction.\n",
        "\n",
        "We will use two datasets that we are now very familiar with:\n",
        " - [Iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)\n",
        " - [MNIST](https://keras.io/api/datasets/mnist/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJl2L7sNQ-zX"
      },
      "source": [
        "\n",
        "## Clustering the Iris dataset\n",
        "\n",
        "Let's get a sense of the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi5yKDwV8Sqn"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# load the data\n",
        "iris = load_iris()\n",
        "\n",
        "# list the keys\n",
        "print(iris.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNwmlzDz27Wz"
      },
      "source": [
        "print(iris['DESCR'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5RucxZp06yS"
      },
      "source": [
        "# read the keys\n",
        "print('feature_names:\\n', iris['feature_names'])\n",
        "print()\n",
        "print('target_names:\\n', iris['target_names'])\n",
        "print()\n",
        "print('data:\\n', iris['data'][:10])\n",
        "print()\n",
        "print('target:\\n', iris['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHj7hStgKPH9"
      },
      "source": [
        "# extract data\n",
        "X = iris.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2jzbohUKT2F"
      },
      "source": [
        "**Remark:** This should be an _unsupervised_ learning setup. So, even though `iris.target` is present, we assume to have no label associated with the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa_Hk2OAu5Sj"
      },
      "source": [
        "#### First of all: shapes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOcsH8-csmMt"
      },
      "source": [
        "print('Shape of X:', X.shape)\n",
        "\n",
        "(n, d) = X.shape\n",
        "print('d:', d)\n",
        "print('n:', n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95GxDfJb7yUj"
      },
      "source": [
        "#### Histograms\n",
        "\n",
        "One component at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXuT8k471qN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(18, 4))\n",
        "\n",
        "for i in range(d):\n",
        "    # a subplot for each feature\n",
        "    plt.subplot(1, d, i+1)\n",
        "\n",
        "    # histogram\n",
        "    plt.hist(X[:, i], density=True, color=f'C{i}')\n",
        "\n",
        "    # axis labels\n",
        "    plt.xlabel('x{}: {}'.format(i, iris.feature_names[i]))\n",
        "    if i == 0:  plt.ylabel('estimated pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkIzyTUHM9Ls"
      },
      "source": [
        "Notice:\n",
        "\n",
        "* the different ranges\n",
        "* `x_2` and `x_3` are roughly bimodal "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYBLsHDH6sFQ"
      },
      "source": [
        "#### Scatter plots \n",
        "\n",
        "More features at the same time.\n",
        "\n",
        "* We have 4 features but we can visualize at most 3D.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHZvlAeD1cAQ"
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "# x0, x1, x2\n",
        "ax = fig.add_subplot(121, projection='3d')\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2])\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_2$')\n",
        "ax.set_zlabel(r'$x_3$')\n",
        "\n",
        "# x0, x2, x3\n",
        "ax = fig.add_subplot(122, projection='3d')\n",
        "ax.scatter(X[:, 0], X[:, 2], X[:, 3])\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_2$')\n",
        "ax.set_zlabel(r'$x_3$')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lD2yrpkPKYb"
      },
      "source": [
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "# x0, x1, x2\n",
        "ax = fig.add_subplot(121, projection='3d', elev=-150, azim=110)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2])\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_2$')\n",
        "ax.set_zlabel(r'$x_3$')\n",
        "\n",
        "# x0, x2, x3\n",
        "ax = fig.add_subplot(122, projection='3d', elev=-150, azim=110)\n",
        "ax.scatter(X[:, 0], X[:, 2], X[:, 3])\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_2$')\n",
        "ax.set_zlabel(r'$x_3$')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPjfnHqLPRDo"
      },
      "source": [
        "Without the right perspective we may miss important clues.\n",
        "* 2D plots are usually clearer than 3D ones (personal opinion!) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmlNJSjX8cJv"
      },
      "source": [
        "def plot_every_pair(X, colors=None, same_axis=False, label_pfx=\"x\"):\n",
        "    d = X.shape[1]\n",
        "    if colors is None:\n",
        "        colors = np.zeros(X.shape[0])\n",
        "    n_plots = d*(d-1)//2\n",
        "    plt.figure(figsize=(3 * n_plots, 8))\n",
        "    ct = 0 \n",
        "    for i in range(1, d+1):\n",
        "        for j in range(i+1, d+1):\n",
        "            ct += 1\n",
        "            plt.subplot(2, max(1, n_plots//2), ct)\n",
        "            plt.scatter(X[:, i-1], X[:, j-1], c=colors)\n",
        "            plt.xlabel(r'${}_{}$'.format(label_pfx, i-1))\n",
        "            plt.ylabel(r'${}_{}$'.format(label_pfx, j-1))\n",
        "            if same_axis:\n",
        "                # Use same axis scaling\n",
        "                plt.xlim([X.min(), X.max()])\n",
        "                plt.ylim([X.min(), X.max()])\n",
        "    plt.show()\n",
        "\n",
        "plot_every_pair(X)               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2YvOsyVQII6"
      },
      "source": [
        "Be careful about the different ranges!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBnwPRvkQNEb"
      },
      "source": [
        "plot_every_pair(X, same_axis=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JpGgWB3QBF4"
      },
      "source": [
        "### Seaborn\n",
        "\n",
        "A cool package for data visualization is `seaborn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcIRy8fPlak"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "sns.pairplot(pd.DataFrame(X, columns=iris.feature_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I70KdBun9jmp"
      },
      "source": [
        "The above visualization is rather difficult when the number of feature is large.\n",
        "\n",
        "## Principal Component Analysis\n",
        "\n",
        "Recall the steps\n",
        "\n",
        "* Subtract the mean\n",
        "* (should we rescale?)\n",
        "* Compute the matrix $\\Sigma = X^\\top X$\n",
        "* Eigen-decomposition $ U \\Lambda U^\\top = \\Sigma$ \n",
        "\n",
        "**Remark 1:** Eigenvalues and eigenvectors: $\\Sigma \\vec u = \\lambda \\vec u$\n",
        "\n",
        "Now apply the transformation\n",
        "1. Lossless rotation $U^\\top \\vec x$ to each vector.\n",
        "2. Lossy transformation:\n",
        "    - Discard some eigenvectors $\\tilde U\\leftarrow U$\n",
        "    - apply transformation $\\tilde U^\\top \\vec x$ to each vector.\n",
        "\n",
        "**Remark 2:** To transform the entire dataset, simply do $XU$ or $X\\tilde U$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDQf58ENAxuv"
      },
      "source": [
        "X_mean = np.mean(X, axis=0, keepdims=True)\n",
        "X0 = X - X_mean\n",
        "\n",
        "Sigma = (X0.T).dot(X0)\n",
        "lam, U = np.linalg.eigh(Sigma)\n",
        "\n",
        "print(\"shapes:\", lam.shape, U.shape)\n",
        "print(\"eigenvalues:\", lam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB4Ohwt9-YRN"
      },
      "source": [
        "# Sort the eigenvalues\n",
        "lam = lam[::-1]\n",
        "U = U[:, ::-1]\n",
        "\n",
        "plt.plot(lam, 'o-')\n",
        "plt.title(\"eigenvalues\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"component\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVozxQ8FBcD1"
      },
      "source": [
        "# Apply rotation\n",
        "X_rot = X0.dot(U)\n",
        "\n",
        "plt.figure(figsize=(18, 4))\n",
        "for i in range(d):\n",
        "    plt.subplot(1, d, i+1)\n",
        "    plt.hist(X_rot[:, i])\n",
        "    plt.xlabel(r'$pc_{}$'.format(i))\n",
        "\n",
        "plot_every_pair(X_rot, same_axis=True, label_pfx=\"pc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRLx6rsl7BlE"
      },
      "source": [
        "# Apply reduced transformation\n",
        "l = 2  # columns to discard\n",
        "Utilde = U[:, :d-l]\n",
        "X_red = X0.dot(Utilde)\n",
        "# Equivalent to X_red = X_rot[:, :d-l]\n",
        "\n",
        "plot_every_pair(X_red, same_axis=True, label_pfx=\"pc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPF8hWfsyxiH"
      },
      "source": [
        "As usual, sklearn can speed up our work!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSBmDO-a8pSt",
        "scrolled": true
      },
      "source": [
        "# PCA with sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# d:    num of original features (= num of all principal components)\n",
        "# l:    num of discarded principal components\n",
        "# d-l:  num of considered principal components\n",
        "pca = PCA(n_components=d-l)\n",
        "pca.fit(X0)\n",
        "X_red = pca.transform(X0)\n",
        "\n",
        "plot_every_pair(X_red, same_axis=True, label_pfx=\"pc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYSb1UB6RZ-"
      },
      "source": [
        "### Data reconstruction\n",
        "\n",
        "$$\\vec x \\to \\vec {\\tilde x} \\to \\vec x_{rec} \\approx \\vec x$$\n",
        "\n",
        "- transformation $\\vec{\\tilde x}=\\tilde U^\\top \\vec x$.\n",
        "- reconstruction (inverse transformation) $\\vec x_{rec} = \\tilde U \\vec{\\tilde x}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnA1N7VUyBT_"
      },
      "source": [
        "# Visualize original vs reconstructed dataset\n",
        "fig = plt.figure(figsize=(18, 4))\n",
        "fig.subplots_adjust(wspace=.4)\n",
        "\n",
        "# Original dataset\n",
        "ax = fig.add_subplot(131, projection='3d', elev=30, azim=160)\n",
        "\n",
        "ax.scatter(X0[:, 0], X0[:, 2], X0[:, 3]) #, X[:, 3])\n",
        "ax.set_xlabel('x_0')\n",
        "ax.set_ylabel('x_2')\n",
        "ax.set_zlabel('x_3')\n",
        "ax.set_title(\"X\")\n",
        "\n",
        "# Principal components\n",
        "ax = fig.add_subplot(132)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1])\n",
        "ax.set_xlabel('pc_0')\n",
        "ax.set_ylabel('pc_1')\n",
        "ax.set_title(\"Principal Components\")\n",
        "ax.axis(\"equal\")\n",
        "\n",
        "# Reconstructed dataset\n",
        "ax = fig.add_subplot(133, projection='3d', elev=30, azim=160)\n",
        "#reconstruct\n",
        "X_rec = pca.inverse_transform(X_red)\n",
        "# #which is equivalent to \n",
        "# X_red_ = X.dot(Utilde)\n",
        "# X_rec_ = X_red_.dot(Utilde.T)\n",
        "\n",
        "ax.scatter(X_rec[:, 0], X_rec[:, 2], X_rec[:, 3]) #, X_rec[:, 3])\n",
        "ax.set_xlabel('x_0')\n",
        "ax.set_ylabel('x_2')\n",
        "ax.set_zlabel('x_3')\n",
        "ax.set_title(\"X reconstructed\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmvk-zM9Tx6y"
      },
      "source": [
        "## Clustering: k-means\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZSFEHNK6sjc"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_clusters = 2\n",
        "\n",
        "k_means = KMeans(n_clusters=k_clusters)\n",
        "cluster_label = k_means.fit_predict(X_red)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEBoYXMX7bHG"
      },
      "source": [
        "# 3d\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "ax = fig.add_subplot(121, projection='3d', elev=30, azim=160)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=cluster_label)\n",
        "# 2d PC\n",
        "ax = fig.add_subplot(122)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=cluster_label)\n",
        "ax.axis(\"equal\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPbfT-xz7n4A"
      },
      "source": [
        "Since we know there are three classes in `iris.target`... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyRzLgYTDEj7"
      },
      "source": [
        "# 3d\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "ax = fig.add_subplot(121, projection='3d', elev=30, azim=160)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=iris.target)\n",
        "plt.title(\"Classes (not clusters!)\")\n",
        "# 2d PC\n",
        "ax = fig.add_subplot(122)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=iris.target)\n",
        "ax.axis(\"equal\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px4OtYmw6UsO"
      },
      "source": [
        "However, k-means (as well as any other clustering method) does not necessarily retrieve the same classes, because classes are not necessarily confined into clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUuGPCB_6TqT"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_clusters = 3\n",
        "\n",
        "k_means = KMeans(n_clusters=k_clusters)\n",
        "cluster_label = k_means.fit_predict(X_red)\n",
        "\n",
        "# 3d\n",
        "fig = plt.figure(figsize=(16, 4))\n",
        "ax = fig.add_subplot(131, projection='3d', elev=30, azim=160)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=cluster_label)\n",
        "# 2d PC\n",
        "ax = fig.add_subplot(132)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=cluster_label)\n",
        "ax.axis(\"equal\")\n",
        "ax.set_title(\"clusters\")\n",
        "\n",
        "# classes\n",
        "ax = fig.add_subplot(133)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=iris.target)\n",
        "ax.axis(\"equal\")\n",
        "ax.set_title(\"classes\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGlmm-BfwRPI"
      },
      "source": [
        "#### Remember\n",
        "\n",
        "- We can cross-validate the number of clusters ([silhouette](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html))\n",
        "- Variety of clustering methods with different behaviours ([comparison](https://scikit-learn.org/stable/modules/clustering.html#clustering)) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTWiyb1b9-Mt"
      },
      "source": [
        "## For fun: MNIST digits compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is1xPVeW-ELd"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def plot_sample(imgs, labels, nrows, ncols, resize=None, tograyscale=False, shuffle=True):\n",
        "    # create a grid of images\n",
        "    fig, axs = plt.subplots(nrows, ncols, figsize=(4*ncols, 4*nrows))\n",
        "    # take a random sample of images\n",
        "    if shuffle:\n",
        "        indices = np.random.choice(len(imgs), size=nrows*ncols, replace=False)\n",
        "    else:\n",
        "        indices = np.arange(nrows*ncols)\n",
        "    for ax, idx in zip(axs.reshape(-1), indices):\n",
        "        ax.axis('off')\n",
        "        # sample an image\n",
        "        ax.set_title(labels[idx])\n",
        "        im = imgs[idx]\n",
        "        if isinstance(im, np.ndarray):\n",
        "            im = Image.fromarray(im)  \n",
        "        if resize is not None:\n",
        "            im = im.resize(resize)\n",
        "        if tograyscale:\n",
        "            im = im.convert('L')\n",
        "        ax.imshow(im, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "plot_sample(x_train, y_train, 2, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfH5vrGYNZWo"
      },
      "source": [
        "Vectorize the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0gdkrdK-PX0"
      },
      "source": [
        "print(\"x_train\", x_train.shape) \n",
        "\n",
        "# Reshape to vectors\n",
        "X = x_train.reshape(-1, 28 * 28) /255.\n",
        "print(\"X\", X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJHcd8K9-a2Z"
      },
      "source": [
        "# PCA\n",
        "X_mean = X.mean(axis=0, keepdims=True)\n",
        "X0 = X - X_mean \n",
        "pca = PCA(n_components=300)\n",
        "pca.fit(X0)\n",
        "\n",
        "plt.plot(pca.singular_values_**2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVAEH-x8Hyy7"
      },
      "source": [
        "# compress\n",
        "X_red = pca.transform(X0)\n",
        "# extract\n",
        "X_rec = pca.inverse_transform(X_red)\n",
        "X_rec += X_mean\n",
        "\n",
        "# reshape to image size and range\n",
        "x_image_rec = 255*X_rec.clip(0, 1).reshape(-1, 28, 28)\n",
        "x_image_orig = 255*X.clip(0, 1).reshape(-1, 28, 28)\n",
        "\n",
        "# draw some random images\n",
        "p = np.random.choice(X.shape[0], size=5)\n",
        "print(\"Original images\")\n",
        "plot_sample(x_image_orig[p], y_train[p], 1, 5, shuffle=False)\n",
        "print(\"Reconstructed images\")\n",
        "plot_sample(x_image_rec[p], y_train[p], 1, 5, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoioU09-_0lz"
      },
      "source": [
        "# Reshape to vectors\n",
        "X = x_train.reshape(-1, 28 * 28) /255.\n",
        "print(X.shape) # shape: (60000, 784)\n",
        "print(X.min(), X.max())\n",
        "X += np.random.randn(*X.shape)*.2\n",
        "\n",
        "# PCA\n",
        "X_mean = X.mean(axis=0, keepdims=True)\n",
        "X0 = X - X_mean \n",
        "pca = PCA(n_components=50)\n",
        "pca.fit(X0)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pca.singular_values_**2)\n",
        "\n",
        "# compress\n",
        "X_red = pca.transform(X0)\n",
        "# extract\n",
        "X_rec = pca.inverse_transform(X_red)\n",
        "X_rec += X_mean\n",
        "\n",
        "# reshape to image size and range\n",
        "x_image_rec = 255*X_rec.clip(0, 1).reshape(-1, 28, 28)\n",
        "x_image_orig = 255*X.clip(0, 1).reshape(-1, 28, 28)\n",
        "\n",
        "# draw some random images\n",
        "p = np.random.choice(X.shape[0], size=5)\n",
        "plot_sample(x_image_orig[p], y_train, 1, 5, shuffle=False)\n",
        "plot_sample(x_image_rec[p], y_train, 1, 5, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgKekvc7QYD_"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for d in range(10):\n",
        "    ii = np.where(y_train==d)[0]\n",
        "    # print(ii)\n",
        "    m = str(d)\n",
        "    # print(m)\n",
        "    # for i in ii:\n",
        "    #     plt.text(X_red[i, 0], X_red[i, 1], str(d), fontsize=12)\n",
        "    plt.scatter(X_red[ii][:, 0], X_red[ii][:, 1], marker=f\"${d}$\", label=d)#str(d))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}