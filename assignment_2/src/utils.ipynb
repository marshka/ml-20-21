{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHiQ2G5Da+562DsAqiwBhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marshka/ml-20-21/blob/main/assignment_2/src/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q9o1iFr2RR1"
      },
      "source": [
        "# Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVEhcaD2y2TK"
      },
      "source": [
        "import os\n",
        "import urllib.request as http\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "\n",
        "\n",
        "def load_cifar10(num_classes=3):\n",
        "    \"\"\"\n",
        "    Downloads CIFAR-10 dataset, which already contains a training and test set,\n",
        "    and return the first `num_classes` classes.\n",
        "    Example of usage:\n",
        "\n",
        "    >>> (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
        "\n",
        "    :param num_classes: int, default is 3 as required by the assignment.\n",
        "    :return: the filtered data.\n",
        "    \"\"\"\n",
        "    (x_train_all, y_train_all), (x_test_all, y_test_all) = cifar10.load_data()\n",
        "\n",
        "    fil_train = tf.where(y_train_all[:, 0] < num_classes)[:, 0]\n",
        "    fil_test = tf.where(y_test_all[:, 0] < num_classes)[:, 0]\n",
        "\n",
        "    y_train = y_train_all[fil_train]\n",
        "    y_test = y_test_all[fil_test]\n",
        "\n",
        "    x_train = x_train_all[fil_train]\n",
        "    x_test = x_test_all[fil_test]\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "\n",
        "def load_rps(download=False, path='rps', reduction_factor=1):\n",
        "    \"\"\"\n",
        "    Downloads the rps dataset and returns the training and test sets.\n",
        "    Example of usage:\n",
        "\n",
        "    >>> (x_train, y_train), (x_test, y_test) = load_rps()\n",
        "\n",
        "    :param download: bool, default is False but for the first call should be True.\n",
        "    :param path: str, subdirectory in which the images should be downloaded, default is 'rps'.\n",
        "    :param reduction_factor: int, factor of reduction of the dataset (len = old_len // reduction_factor).\n",
        "    :return: the images and labels split into training and validation sets.\n",
        "    \"\"\"\n",
        "    url = 'https://drive.switch.ch/index.php/s/xjXhuYDUzoZvL02/download'\n",
        "    classes = ('rock', 'paper', 'scissors')\n",
        "    rps_dir = os.path.abspath(path)\n",
        "    filename = os.path.join(rps_dir, 'data.zip')\n",
        "    if not os.path.exists(rps_dir) and not download:\n",
        "        raise ValueError(\"Dataset not in the path. You should call this function with `download=True` the first time.\")\n",
        "    if download:\n",
        "        os.makedirs(rps_dir, exist_ok=True)\n",
        "        print(f\"Downloading rps images in {rps_dir} (may take a couple of minutes)\")\n",
        "        path, msg = http.urlretrieve(url, filename)\n",
        "        with ZipFile(path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(rps_dir)\n",
        "        os.remove(filename)\n",
        "    train_dir, test_dir = os.path.join(rps_dir, 'train'), os.path.join(rps_dir, 'test')\n",
        "    print(\"Loading training set...\")\n",
        "    x_train, y_train = load_images_with_label(train_dir, classes)\n",
        "    x_train, y_train = x_train[::reduction_factor], y_train[::reduction_factor]\n",
        "    print(\"Loaded %d images for training\" % len(y_train))\n",
        "    print(\"Loading test set...\")\n",
        "    x_test, y_test = load_images_with_label(test_dir, classes)\n",
        "    x_test, y_test = x_test[::reduction_factor], y_test[::reduction_factor]\n",
        "    print(\"Loaded %d images for testing\" % len(y_test))\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "\n",
        "def make_dataset(imgs, labels, label_map, img_size, rgb=True, keepdim=True, shuffle=True):\n",
        "    x = []\n",
        "    y = []\n",
        "    n_classes = len(list(label_map.keys()))\n",
        "    for im, l in zip(imgs, labels):\n",
        "        # preprocess img\n",
        "        x_i = im.resize(img_size)\n",
        "        if not rgb:\n",
        "            x_i = x_i.convert('L')\n",
        "        x_i = np.asarray(x_i)\n",
        "        if not keepdim:\n",
        "            x_i = x_i.reshape(-1)\n",
        "        \n",
        "        # encode label\n",
        "        y_i = np.zeros(n_classes)\n",
        "        y_i[label_map[l]] = 1.\n",
        "        \n",
        "        x.append(x_i)\n",
        "        y.append(y_i)\n",
        "    x, y = np.array(x).astype('float32'), np.array(y)\n",
        "    if shuffle:\n",
        "        idxs = np.arange(len(y))\n",
        "        np.random.shuffle(idxs)\n",
        "        x, y = x[idxs], y[idxs]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def load_images(path):\n",
        "    img_files = os.listdir(path)\n",
        "    imgs, labels = [], []\n",
        "    for i in img_files:\n",
        "        if i.endswith('.jpg'):\n",
        "            # load the image (here you might want to resize the img to save memory)\n",
        "            imgs.append(Image.open(os.path.join(path, i)).copy())\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def load_images_with_label(path, classes):\n",
        "    imgs, labels = [], []\n",
        "    for c in classes:\n",
        "        # iterate over all the files in the folder\n",
        "        c_imgs = load_images(os.path.join(path, c))\n",
        "        imgs.extend(c_imgs)\n",
        "        labels.extend([c] * len(c_imgs))\n",
        "    return imgs, labels\n",
        "\n",
        "\n",
        "def save_keras_model(model, filename):\n",
        "    \"\"\"\n",
        "    Saves a Keras model to disk.\n",
        "    Example of usage:\n",
        "\n",
        "    >>> model = Sequential()\n",
        "    >>> model.add(Dense(...))\n",
        "    >>> model.compile(...)\n",
        "    >>> model.fit(...)\n",
        "    >>> save_keras_model(model, 'my_model.h5')\n",
        "\n",
        "    :param model: the model to save;\n",
        "    :param filename: string, path to the file in which to store the model.\n",
        "    :return: the model.\n",
        "    \"\"\"\n",
        "    save_model(model, filename)\n",
        "\n",
        "\n",
        "def load_keras_model(filename):\n",
        "    \"\"\"\n",
        "    Loads a compiled Keras model saved with models.save_model.\n",
        "\n",
        "    :param filename: string, path to the file storing the model.\n",
        "    :return: the model.\n",
        "    \"\"\"\n",
        "    model = load_model(filename)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxvuMnmmzAfa"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_rps(download=True, reduction_factor=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y7BB803177D"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_cifar10(num_classes=3)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}